{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import logging\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder,MinMaxScaler, Normalizer, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from mlxtend.preprocessing import DenseTransformer\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "sns.set(color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('ai')\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='%(asctime)s  %(filename)s : %(levelname)s  %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, '%d.%m.%Y')\n",
    "sales_df = pd.read_csv('../input/sales_train.csv', parse_dates = ['date'], date_parser=dateparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = pd.read_csv('../input/items.csv')\n",
    "shop_df = pd.read_csv('../input/shops.csv')\n",
    "category_df = pd.read_csv('../input/item_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('../input/test.csv').set_index('ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear the data out of range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-13 21:41:01,602  <ipython-input-6-ea685e07fb41> : INFO  item_price more than 100000 is 1\n",
      "2019-02-13 21:41:01,609  <ipython-input-6-ea685e07fb41> : INFO  item_cnt_day more than 1000 is 1\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"item_price more than 100000 is %d\" % sales_df[sales_df.item_price > 100000].shape[0])\n",
    "logger.info(\"item_cnt_day more than 1000 is %d\" % sales_df[sales_df.item_cnt_day > 1000].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = sales_df[sales_df.item_price<100000]\n",
    "sales_df = sales_df[sales_df.item_cnt_day<1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the negative item price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_cnt_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>484683</th>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>2973</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  date_block_num  shop_id  item_id  item_price  item_cnt_day\n",
       "484683 2013-05-15               4       32     2973        -1.0           1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_df[sales_df.item_price < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.at[484683, 'item_price'] = sales_df[(sales_df.item_id == 2973) & (sales_df.item_price > 0)].item_price.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust duplicates by shop name\n",
    "\n",
    "According to the reference, some shops are duplicates. This feature found is based on the language background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_name</th>\n",
       "      <th>shop_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>!Якутск Орджоникидзе, 56 фран</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       shop_name  shop_id\n",
       "0  !Якутск Орджоникидзе, 56 фран        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_df[shop_df.shop_id == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_name</th>\n",
       "      <th>shop_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Якутск Орджоникидзе, 56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  shop_name  shop_id\n",
       "57  Якутск Орджоникидзе, 56       57"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shop_df[shop_df.shop_id == 57]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shop_id 0 and 57 are the same shop. And other pairs are 1 and 58, 10 and 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Якутск Орджоникидзе, 56\n",
    "sales_df.at[sales_df.shop_id == 0, 'shop_id'] = 57\n",
    "# Якутск ТЦ \"Центральный\"\n",
    "sales_df.at[sales_df.shop_id == 1, 'shop_id'] = 58\n",
    "# Жуковский ул. Чкалова 39м²\n",
    "sales_df.at[sales_df.shop_id == 10, 'shop_id'] = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Data into one entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_detail_df = sales_df.groupby(['shop_id', 'item_id', 'date_block_num'])['item_cnt_day'].sum().reset_index(name='item_cnt_month')\n",
    "sales_price_df = sales_df.groupby(['shop_id', 'item_id', 'date_block_num'])['item_price'].mean().reset_index(name='item_avg_price')\n",
    "\n",
    "sales_detail_df = pd.merge(sales_detail_df, sales_price_df, on=['shop_id', 'item_id', 'date_block_num'], how='left')\n",
    "sales_detail_df = pd.merge(sales_detail_df, item_df, on=['item_id'], how='left')\n",
    "sales_detail_df = pd.merge(sales_detail_df, shop_df, on=['shop_id'], how='left')\n",
    "sales_detail_df = pd.merge(sales_detail_df, category_df, on=['item_category_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Feature 'city'**: Each shop_name starts with the city name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_detail_df.loc[sales_detail_df.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n",
    "sales_detail_df['city'] = sales_detail_df['shop_name'].str.split(' ').map(lambda x: x[0])\n",
    "sales_detail_df.loc[sales_detail_df.city == '!Якутск', 'city'] = 'Якутск'\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(sales_detail_df['city'])\n",
    "sales_detail_df['city_code'] = encoder.transform(sales_detail_df['city'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Feature 'type'**: Each category contains type and subtype in its name.\n",
    "+ **Feature 'subtype'**: Each category contains type and subtype in its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_detail_df['type'] = sales_detail_df['item_category_name'].map(lambda x: x.split('-')[0].strip())\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(sales_detail_df['type'])\n",
    "sales_detail_df['type_code'] = encoder.transform(sales_detail_df['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_detail_df['subtype'] = sales_detail_df['item_category_name'].map(lambda x: x.split('-')[1].strip() if len(x.split('-')) > 1 else x.split('-')[0].strip())\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(sales_detail_df['subtype'])\n",
    "sales_detail_df['subtype_code'] = encoder.transform(sales_detail_df['subtype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_detail_df['month'] = sales_detail_df['date_block_num'].apply(lambda x: (x % 12) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Feature 'p'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 13, 1):\n",
    "    t = sales_feature_df['shop_id', 'item_category_id', 'date_block_num', 'item_cnt_month']\n",
    "    t['date_block_num'] = t['date_block_num'] + i\n",
    "    t = t.rename(index=str, columns={'date_block_num': 'p'+str(i)})\n",
    "    sales_detail_df = pd.merge(sales_detail_df, t, on=['shop_id', 'item_category_id', 'date_block_num'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Feature 'sc'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sales_detail_df.groupby(['shop_id', 'item_category_id', 'date_block_num'])['item_cnt_month'].mean().reset_index(name='sc1')\n",
    "sales_detail_df = pd.merge(sales_detail_df, t, on=['shop_id', 'item_category_id', 'date_block_num'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sales_detail_df.groupby(['shop_id', 'item_category_id', 'date_block_num'])['item_avg_price'].mean().reset_index(name='sc2')\n",
    "sales_detail_df = pd.merge(sales_detail_df, t, on=['shop_id', 'item_category_id', 'date_block_num'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Feature 'st1'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sales_detail_df.groupby(['shop_id', 'type_code', 'date_block_num'])['item_cnt_month'].mean().reset_index(name='st1')\n",
    "sales_detail_df = pd.merge(sales_detail_df, t, on=['shop_id', 'type_code', 'date_block_num'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Feature 'c1'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sales_detail_df.groupby(['city', 'date_block_num'])['item_cnt_month'].mean().reset_index(name='c1')\n",
    "sales_detail_df = pd.merge(sales_detail_df, t, on=['city', 'date_block_num'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Feature 'i1'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sales_detail_df.groupby(['item_id', 'date_block_num'])['item_cnt_month'].mean().reset_index(name='i1')\n",
    "sales_detail_df = pd.merge(sales_detail_df, t, on=['item_id', 'date_block_num'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Feature 's1'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sales_detail_df.groupby(['shop_id', 'date_block_num'])['item_cnt_month'].mean().reset_index(name='s1')\n",
    "sales_detail_df = pd.merge(sales_detail_df, t, on=['shop_id', 'date_block_num'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Feature 'cat1'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = sales_detail_df.groupby(['item_category_id', 'date_block_num'])['item_cnt_month'].mean().reset_index(name='cat1')\n",
    "sales_detail_df = pd.merge(sales_detail_df, t, on=['item_category_id', 'date_block_num'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sales_detail_df[sales_detail_df.date_block_num > 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['shop_id', 'item_id', 'date_block_num', 'item_cnt_month',\n",
       "       'item_avg_price', 'item_name', 'item_category_id', 'shop_name',\n",
       "       'item_category_name', 'city', 'city_code', 'type', 'type_code',\n",
       "       'subtype', 'subtype_code', 'month', 'sc1', 'c1', 'i1', 's1',\n",
       "       'cat1', 'st1', 'sc2'], dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous = [\n",
    "    'shop_id', 'item_id', 'date_block_num', 'item_avg_price', 'item_category_id', 'city_code', 'type_code', 'subtype_code', 'month', 'sc1', 'c1', 'i1', 's1', 'cat1', 'st1', 'sc2',\n",
    "    'p1','p2','p3','p4','p5','p6','p7','p8','p9','p10','p11','p12',\n",
    "]\n",
    "\n",
    "fields = [\n",
    "    \n",
    "]\n",
    "\n",
    "label = ['item_cnt_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_processor = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('continuous', Pipeline([\n",
    "            ('extract', ColumnSelector(continuous)),\n",
    "            ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "        ])),\n",
    "#         ('fields', Pipeline([\n",
    "#             ('extract', ColumnSelector(fields)),\n",
    "#             ('imputer', SimpleImputer(missing_values=np.nan,  strategy='most_frequent')),\n",
    "#             ('one_hot', OneHotEncoder(categories='auto')),\n",
    "#             ('to_dense', DenseTransformer())\n",
    "#         ])),\n",
    "    ])),\n",
    "])\n",
    "\n",
    "feature_processor.fit(dataset, dataset[label].values.ravel())\n",
    "selector_model = XGBRegressor(max_depth=3, n_estimators=20, random_state=0)\n",
    "selector_model.fit(feature_processor.transform(dataset), dataset[label].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selector = []\n",
    "for index, value in enumerate(selector_model.feature_importances_):\n",
    "    if value > 0 and index < len(continuous):\n",
    "        feature_selector.append((continuous[index], value))\n",
    "\n",
    "feature_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.replace([np.inf, -np.inf], np.nan)\n",
    "dataset = dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_beta = dataset[dataset.date_block_num < 33]\n",
    "dataset_alpha = dataset[dataset.date_block_num == 33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('continuous', Pipeline([\n",
    "            ('extract', ColumnSelector(continuous)),\n",
    "            ('imputer', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "        ])),\n",
    "    ])),\n",
    "])\n",
    "\n",
    "features_pipeline.fit(dataset_beta, dataset_beta[label].values.ravel())\n",
    "\n",
    "train_dataset_x = features_pipeline.transform(dataset_beta)\n",
    "train_dataset_y = dataset_beta[label].values.ravel()\n",
    "\n",
    "valid_dataset_x = features_pipeline.transform(dataset_alpha)\n",
    "valid_dataset_y = dataset_alpha[label].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:8.12133\tvalidation_1-rmse:6.82314\n",
      "Multiple eval metrics have been passed: 'validation_1-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-rmse hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-rmse:7.63465\tvalidation_1-rmse:6.30553\n",
      "[2]\tvalidation_0-rmse:7.21255\tvalidation_1-rmse:5.86196\n",
      "[3]\tvalidation_0-rmse:6.84975\tvalidation_1-rmse:5.55863\n",
      "[4]\tvalidation_0-rmse:6.52073\tvalidation_1-rmse:5.2173\n",
      "[5]\tvalidation_0-rmse:6.23961\tvalidation_1-rmse:5.06724\n",
      "[6]\tvalidation_0-rmse:6.02318\tvalidation_1-rmse:4.808\n",
      "[7]\tvalidation_0-rmse:5.79232\tvalidation_1-rmse:4.55196\n",
      "[8]\tvalidation_0-rmse:5.58479\tvalidation_1-rmse:4.3106\n",
      "[9]\tvalidation_0-rmse:5.4119\tvalidation_1-rmse:4.11212\n",
      "[10]\tvalidation_0-rmse:5.26952\tvalidation_1-rmse:3.94863\n",
      "[11]\tvalidation_0-rmse:5.1512\tvalidation_1-rmse:3.82239\n",
      "[12]\tvalidation_0-rmse:5.04929\tvalidation_1-rmse:3.72502\n",
      "[13]\tvalidation_0-rmse:4.96511\tvalidation_1-rmse:3.6394\n",
      "[14]\tvalidation_0-rmse:4.89638\tvalidation_1-rmse:3.57483\n",
      "[15]\tvalidation_0-rmse:4.82543\tvalidation_1-rmse:3.49217\n",
      "[16]\tvalidation_0-rmse:4.7703\tvalidation_1-rmse:3.44442\n",
      "[17]\tvalidation_0-rmse:4.72654\tvalidation_1-rmse:3.3985\n",
      "[18]\tvalidation_0-rmse:4.68274\tvalidation_1-rmse:3.34468\n",
      "[19]\tvalidation_0-rmse:4.62761\tvalidation_1-rmse:3.30817\n",
      "[20]\tvalidation_0-rmse:4.60831\tvalidation_1-rmse:3.28337\n",
      "[21]\tvalidation_0-rmse:4.58919\tvalidation_1-rmse:3.2639\n",
      "[22]\tvalidation_0-rmse:4.57278\tvalidation_1-rmse:3.23898\n",
      "[23]\tvalidation_0-rmse:4.54567\tvalidation_1-rmse:3.21345\n",
      "[24]\tvalidation_0-rmse:4.52045\tvalidation_1-rmse:3.18717\n",
      "[25]\tvalidation_0-rmse:4.50186\tvalidation_1-rmse:3.18009\n",
      "[26]\tvalidation_0-rmse:4.46537\tvalidation_1-rmse:3.16658\n",
      "[27]\tvalidation_0-rmse:4.43253\tvalidation_1-rmse:3.1721\n",
      "[28]\tvalidation_0-rmse:4.41678\tvalidation_1-rmse:3.15867\n",
      "[29]\tvalidation_0-rmse:4.39119\tvalidation_1-rmse:3.15013\n",
      "[30]\tvalidation_0-rmse:4.36948\tvalidation_1-rmse:3.15302\n",
      "[31]\tvalidation_0-rmse:4.35699\tvalidation_1-rmse:3.13929\n",
      "[32]\tvalidation_0-rmse:4.34884\tvalidation_1-rmse:3.14159\n",
      "[33]\tvalidation_0-rmse:4.33872\tvalidation_1-rmse:3.13223\n",
      "[34]\tvalidation_0-rmse:4.33104\tvalidation_1-rmse:3.13016\n",
      "[35]\tvalidation_0-rmse:4.32413\tvalidation_1-rmse:3.12114\n",
      "[36]\tvalidation_0-rmse:4.31811\tvalidation_1-rmse:3.12039\n",
      "[37]\tvalidation_0-rmse:4.31179\tvalidation_1-rmse:3.1195\n",
      "[38]\tvalidation_0-rmse:4.30434\tvalidation_1-rmse:3.11413\n",
      "[39]\tvalidation_0-rmse:4.2982\tvalidation_1-rmse:3.11448\n",
      "[40]\tvalidation_0-rmse:4.29314\tvalidation_1-rmse:3.11309\n",
      "[41]\tvalidation_0-rmse:4.29171\tvalidation_1-rmse:3.11109\n",
      "[42]\tvalidation_0-rmse:4.2838\tvalidation_1-rmse:3.10329\n",
      "[43]\tvalidation_0-rmse:4.28037\tvalidation_1-rmse:3.10544\n",
      "[44]\tvalidation_0-rmse:4.27791\tvalidation_1-rmse:3.10116\n",
      "[45]\tvalidation_0-rmse:4.27502\tvalidation_1-rmse:3.10689\n",
      "[46]\tvalidation_0-rmse:4.26984\tvalidation_1-rmse:3.10003\n",
      "[47]\tvalidation_0-rmse:4.26524\tvalidation_1-rmse:3.09409\n",
      "[48]\tvalidation_0-rmse:4.2641\tvalidation_1-rmse:3.09449\n",
      "[49]\tvalidation_0-rmse:4.2587\tvalidation_1-rmse:3.09581\n",
      "[50]\tvalidation_0-rmse:4.25571\tvalidation_1-rmse:3.09772\n",
      "[51]\tvalidation_0-rmse:4.25307\tvalidation_1-rmse:3.09752\n",
      "[52]\tvalidation_0-rmse:4.2513\tvalidation_1-rmse:3.09803\n",
      "[53]\tvalidation_0-rmse:4.24797\tvalidation_1-rmse:3.10162\n",
      "[54]\tvalidation_0-rmse:4.24492\tvalidation_1-rmse:3.10183\n",
      "[55]\tvalidation_0-rmse:4.24336\tvalidation_1-rmse:3.10433\n",
      "[56]\tvalidation_0-rmse:4.24081\tvalidation_1-rmse:3.10751\n",
      "[57]\tvalidation_0-rmse:4.237\tvalidation_1-rmse:3.11003\n",
      "Stopping. Best iteration:\n",
      "[47]\tvalidation_0-rmse:4.26524\tvalidation_1-rmse:3.09409\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eta=0.3, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=300, missing=None,\n",
       "       n_estimators=1000, n_jobs=1, nthread=None, objective='reg:linear',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=10, scale_pos_weight=1,\n",
       "       seed=2018, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "model = XGBRegressor(\n",
    "    max_depth=8,\n",
    "    n_estimators=1000,\n",
    "    min_child_weight=300, \n",
    "    colsample_bytree=0.8, \n",
    "    subsample=0.8, \n",
    "    reg_lambda=10,\n",
    "    eta=0.3,    \n",
    "    seed=2018)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset_x, \n",
    "    train_dataset_y, \n",
    "    eval_metric=\"rmse\", \n",
    "    eval_set=[(train_dataset_x, train_dataset_y), (valid_dataset_x, valid_dataset_y)], \n",
    "    verbose=True, \n",
    "    early_stopping_rounds = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('../features/' + FILENAME + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal ML Analysis\n",
    "\n",
    "+ [Feature engineering, xgboost](https://www.kaggle.com/dlarionov/feature-engineering-xgboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series\n",
    "\n",
    "对于revenge的预测很有帮助，但是对于单个店的单个商品而言没有实际的意义，这种预测方式的学习非常有益处\n",
    "\n",
    "+ [AR(I)MA时间序列建模过程——步骤和python代码](https://www.jianshu.com/p/cced6617b423)\n",
    "+ [python时间序列分析](http://www.cnblogs.com/foley/p/5582358.html)\n",
    "+ [AR、MA及ARMA模型](https://zhuanlan.zhihu.com/p/22248464)\n",
    "+ [Time Series with Python (ODSC) STA.ipynb](https://github.com/ultimatist/ODSC17/blob/master/Time%20Series%20with%20Python%20(ODSC)%20STA.ipynb)\n",
    "+ [Getting Started with Time Series](https://pyflux.readthedocs.io/en/latest/getting_started.html)\n",
    "+ [Welcome to Statsmodels’s Documentation](http://www.statsmodels.org/devel/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
